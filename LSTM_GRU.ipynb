{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# LSTM and GRU \n","metadata":{}},{"cell_type":"markdown","source":"# PyTorch Implementation","metadata":{}},{"cell_type":"code","source":"# importing required libraries \n\nimport pandas as pd\n\n# for pytorch imports\nimport torch\n\n# for functional dependencies like activation function \nimport torch.nn.functional as F\n\n# nn is basic module in Torch which provide different neural network architecture\nimport torch.nn as nn\n\n# for optimizer\nimport torch.optim as optim\n\n# CountVectorizer for Bagof words model\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# for padding .. since the LSTM takes input as sequence so it is said that \n#if we have fixed input string computation will be faster and it will improve performance \nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm, tqdm_notebook\nfrom torch.utils.data import random_split","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.021605Z","iopub.execute_input":"2022-09-01T06:55:12.021946Z","iopub.status.idle":"2022-09-01T06:55:12.027636Z","shell.execute_reply.started":"2022-09-01T06:55:12.021916Z","shell.execute_reply":"2022-09-01T06:55:12.026626Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# GPU ..... vrooom vrooom vroooooooooom !!!!\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.029229Z","iopub.execute_input":"2022-09-01T06:55:12.029945Z","iopub.status.idle":"2022-09-01T06:55:12.045163Z","shell.execute_reply.started":"2022-09-01T06:55:12.029909Z","shell.execute_reply":"2022-09-01T06:55:12.044291Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Class Sequences :\n- it will take text dataset as input and processed the text, tokenize it to sequences, pad it\n- function __getitem__ willl return the item at particular index\n- __len__ return lenght of the sequence","metadata":{}},{"cell_type":"code","source":"class Sequences(Dataset):\n    def __init__(self, path, max_seq_len):\n        self.max_seq_len = max_seq_len\n        df = path\n        \n        # BOW \n        vectorizer = CountVectorizer(stop_words='english', min_df=0.015)\n        vectorizer.fit(df.review.tolist())\n        \n        # Creating Vocabulary\n        self.token2idx = vectorizer.vocabulary_\n        \n        self.token2idx['<PAD>'] = max(self.token2idx.values()) + 1\n\n        tokenizer = vectorizer.build_analyzer()\n        self.encode = lambda x: [self.token2idx[token] for token in tokenizer(x)\n                                 if token in self.token2idx]\n        self.pad = lambda x: x + (max_seq_len - len(x)) * [self.token2idx['<PAD>']]\n        \n        sequences = [self.encode(sequence)[:max_seq_len] for sequence in df.review.tolist()]\n        sequences, self.labels = zip(*[(sequence, label) for sequence, label\n                                    in zip(sequences, df.label.tolist()) if sequence])\n        self.sequences = [self.pad(sequence) for sequence in sequences]\n\n    def __getitem__(self, i):\n        assert len(self.sequences[i]) == self.max_seq_len\n        return self.sequences[i], self.labels[i]\n    \n    def __len__(self):\n        return len(self.sequences)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.047271Z","iopub.execute_input":"2022-09-01T06:55:12.048018Z","iopub.status.idle":"2022-09-01T06:55:12.057533Z","shell.execute_reply.started":"2022-09-01T06:55:12.047977Z","shell.execute_reply":"2022-09-01T06:55:12.056580Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data  = pd.read_csv(r'../input/traindataset/Train dataset.csv')\ndata['label'] = data['sentiment']\ndel data['sentiment']\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.059138Z","iopub.execute_input":"2022-09-01T06:55:12.059646Z","iopub.status.idle":"2022-09-01T06:55:12.487898Z","shell.execute_reply.started":"2022-09-01T06:55:12.059605Z","shell.execute_reply":"2022-09-01T06:55:12.487043Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"__Encoding positive as 1 and negative as 0__","metadata":{}},{"cell_type":"code","source":"labeling = {\n    'positive':1, \n    'negative':0\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.489201Z","iopub.execute_input":"2022-09-01T06:55:12.489531Z","iopub.status.idle":"2022-09-01T06:55:12.493917Z","shell.execute_reply.started":"2022-09-01T06:55:12.489496Z","shell.execute_reply":"2022-09-01T06:55:12.492724Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data['label'] = data['label'].apply(lambda x : labeling[x])\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.495421Z","iopub.execute_input":"2022-09-01T06:55:12.495773Z","iopub.status.idle":"2022-09-01T06:55:12.517551Z","shell.execute_reply.started":"2022-09-01T06:55:12.495733Z","shell.execute_reply":"2022-09-01T06:55:12.516608Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.519314Z","iopub.execute_input":"2022-09-01T06:55:12.519842Z","iopub.status.idle":"2022-09-01T06:55:12.528173Z","shell.execute_reply.started":"2022-09-01T06:55:12.519806Z","shell.execute_reply":"2022-09-01T06:55:12.527326Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# feeding data in class and getting its instance in return \ndataset = Sequences(data, max_seq_len=200)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:12.531075Z","iopub.execute_input":"2022-09-01T06:55:12.531377Z","iopub.status.idle":"2022-09-01T06:55:23.014430Z","shell.execute_reply.started":"2022-09-01T06:55:12.531349Z","shell.execute_reply":"2022-09-01T06:55:23.013555Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"len(dataset.token2idx)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.017073Z","iopub.execute_input":"2022-09-01T06:55:23.017434Z","iopub.status.idle":"2022-09-01T06:55:23.024972Z","shell.execute_reply.started":"2022-09-01T06:55:23.017397Z","shell.execute_reply":"2022-09-01T06:55:23.023913Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def collate(batch):\n    inputs = torch.LongTensor([item[0] for item in batch])\n    target = torch.FloatTensor([item[1] for item in batch])\n    return inputs, target\n\nbatch_size = 512\n# train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)\ntraining, validation = random_split(dataset, [35000, 5000])","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.026647Z","iopub.execute_input":"2022-09-01T06:55:23.027038Z","iopub.status.idle":"2022-09-01T06:55:23.035781Z","shell.execute_reply.started":"2022-09-01T06:55:23.027004Z","shell.execute_reply":"2022-09-01T06:55:23.034903Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset=training, batch_size=batch_size, shuffle=True, collate_fn=collate)\nval_loader = torch.utils.data.DataLoader(dataset=validation, batch_size=batch_size, shuffle=True, collate_fn=collate)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.036947Z","iopub.execute_input":"2022-09-01T06:55:23.037250Z","iopub.status.idle":"2022-09-01T06:55:23.043105Z","shell.execute_reply.started":"2022-09-01T06:55:23.037215Z","shell.execute_reply":"2022-09-01T06:55:23.042048Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\n\nclass RNN(nn.Module):\n    def __init__(\n        self,\n        vocab_size,\n        batch_size,\n        embedding_dimension=100,\n        hidden_size=200, \n        n_layers=1,\n        device='cpu'\n    ):\n        super(RNN, self).__init__()\n        self.n_layers = n_layers\n        self.hidden_size = hidden_size\n        self.device = device\n        self.batch_size = batch_size\n        self.encoder = nn.Embedding(vocab_size, embedding_dimension)\n        self.rnn = nn.LSTM(\n            embedding_dimension,\n            hidden_size,\n            num_layers=n_layers,\n            batch_first=True,\n        )\n        self.decoder = nn.Linear(hidden_size, 1)\n        \n    def init_hidden(self ):\n        \n        return (torch.randn(self.n_layers, self.batch_size, self.hidden_size).to(self.device),\n                torch.randn(self.n_layers, self.batch_size, self.hidden_size).to(self.device) )\n       \n    \n    def forward(self, inputs):\n        # Avoid breaking if the last batch has a different size\n        batch_size = inputs.size(0)\n        if batch_size != self.batch_size:\n            self.batch_size = batch_size\n            \n        encoded = self.encoder(inputs)\n        output, hidden = self.rnn(encoded, self.init_hidden())\n        #o\n        output = self.decoder(output[:, :, -1]).squeeze()\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.044335Z","iopub.execute_input":"2022-09-01T06:55:23.044667Z","iopub.status.idle":"2022-09-01T06:55:23.056496Z","shell.execute_reply.started":"2022-09-01T06:55:23.044633Z","shell.execute_reply":"2022-09-01T06:55:23.055562Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = RNN(\n    hidden_size=200,\n    vocab_size=len(dataset.token2idx),\n    device=device,\n    batch_size=batch_size\n)\nmodel = model.to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.058835Z","iopub.execute_input":"2022-09-01T06:55:23.059403Z","iopub.status.idle":"2022-09-01T06:55:23.074947Z","shell.execute_reply.started":"2022-09-01T06:55:23.059367Z","shell.execute_reply":"2022-09-01T06:55:23.073834Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.076321Z","iopub.execute_input":"2022-09-01T06:55:23.076716Z","iopub.status.idle":"2022-09-01T06:55:23.081316Z","shell.execute_reply.started":"2022-09-01T06:55:23.076678Z","shell.execute_reply":"2022-09-01T06:55:23.080473Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"model.train()\ntrain_losses = []\nval_losses = []\nfor epoch in range(10):\n    progress_bar = tqdm_notebook(train_loader, leave=False)\n    losses = []\n    total = 0\n    accuracyListPred = []\n    for inputs, target in progress_bar:\n        inputs, target = inputs.to(device), target.to(device)\n        model.zero_grad()\n        \n        output = model(inputs)\n    \n        loss = criterion(output, target)\n        \n        loss.backward()\n              \n        nn.utils.clip_grad_norm_(model.parameters(), 3)\n\n        optimizer.step()\n        \n        progress_bar.set_description(f'Loss: {loss.item():.3f}')\n        \n        losses.append(loss.item())\n        total += 1\n    \n    epoch_loss = sum(losses) / total\n    train_losses.append(epoch_loss)\n    \n    \n    progress_bar_val = tqdm_notebook(val_loader, leave=False)\n    losses = []\n    total = 0\n    for inputs, target in progress_bar_val:\n#         model.eval()\n        inputs, target = inputs.to(device), target.to(device)\n#         model.zero_grad()\n        \n        output = model(inputs)\n    \n        loss = criterion(output, target)\n        \n#         progress_bar.set_description(f'Loss: {loss.item():.3f}')\n        \n        losses.append(loss.item())\n        total += 1\n        prediction = torch.sigmoid(output.detach())\n        for i in range(len(prediction)):\n            if(prediction[i] > 0.5):\n                prediction[i] = 1\n            else:\n                prediction[i] = 0\n#         print(len(prediction))\n        \n        accuracyListPred.append(target.eq(prediction).float().mean())\n    \n    accuracy = torch.tensor(accuracyListPred).mean() * 100\n    epoch_loss_val = sum(losses) / total\n    val_losses.append(epoch_loss_val)\n\n    tqdm.write(f'Epoch #{epoch + 1}\\tTrain Loss: {epoch_loss:.3f}\\Val Loss: {epoch_loss_val:.3f}\\tAccuracy: {accuracy:.3f}')\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:55:23.082621Z","iopub.execute_input":"2022-09-01T06:55:23.083181Z","iopub.status.idle":"2022-09-01T06:56:05.812424Z","shell.execute_reply.started":"2022-09-01T06:55:23.083148Z","shell.execute_reply":"2022-09-01T06:56:05.811562Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def predict_sentiment(text):\n    model.eval()\n    with torch.no_grad():\n        test_vector = torch.LongTensor([dataset.pad(dataset.encode(text))]).to(device)\n        \n        output = model(test_vector)\n        prediction = torch.sigmoid(output).item()\n\n        if prediction > 0.5:\n            print(f'{prediction:0.3}: Positive sentiment')\n        else:\n            print(f'{prediction:0.3}: Negative sentiment')","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.813679Z","iopub.execute_input":"2022-09-01T06:56:05.814168Z","iopub.status.idle":"2022-09-01T06:56:05.820906Z","shell.execute_reply.started":"2022-09-01T06:56:05.814130Z","shell.execute_reply":"2022-09-01T06:56:05.819983Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"text= \"that's nice\"\npredict_sentiment(text)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.822002Z","iopub.execute_input":"2022-09-01T06:56:05.822389Z","iopub.status.idle":"2022-09-01T06:56:05.842572Z","shell.execute_reply.started":"2022-09-01T06:56:05.822354Z","shell.execute_reply":"2022-09-01T06:56:05.841738Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"text= \"that's worst\"\npredict_sentiment(text)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.843968Z","iopub.execute_input":"2022-09-01T06:56:05.844553Z","iopub.status.idle":"2022-09-01T06:56:05.853849Z","shell.execute_reply.started":"2022-09-01T06:56:05.844512Z","shell.execute_reply":"2022-09-01T06:56:05.852788Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# QUOTE FROM RICH DAD POOR DAD\ntext= \"In school we learn that mistakes are bad, and we are punished for making them. Yet, if you look at the way humans are designed to learn, we learn by making mistakes. We learn to walk by falling down. If we never fell down, we would never walk\"\nprint(text)\n\npredict_sentiment(text)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.855365Z","iopub.execute_input":"2022-09-01T06:56:05.855735Z","iopub.status.idle":"2022-09-01T06:56:05.865996Z","shell.execute_reply.started":"2022-09-01T06:56:05.855681Z","shell.execute_reply":"2022-09-01T06:56:05.865043Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"I love this car.\nThis view is amazing.\nI feel great this morning.\nI am so excited about the concert.\nHe is my best friend\n\"\"\"\npredict_sentiment(text)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.867546Z","iopub.execute_input":"2022-09-01T06:56:05.868108Z","iopub.status.idle":"2022-09-01T06:56:05.878097Z","shell.execute_reply.started":"2022-09-01T06:56:05.868070Z","shell.execute_reply":"2022-09-01T06:56:05.876746Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"text=\"\"\"\nI do not like this car.\nThis view is horrible.\nI feel tired this morning.\nI am not looking forward to the concert.\nHe is my enemy\n\"\"\"\npredict_sentiment(text)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T06:56:05.879497Z","iopub.execute_input":"2022-09-01T06:56:05.880143Z","iopub.status.idle":"2022-09-01T06:56:05.888950Z","shell.execute_reply.started":"2022-09-01T06:56:05.880109Z","shell.execute_reply":"2022-09-01T06:56:05.887914Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"References : \n\nhttps://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n\nhttps://towardsdatascience.com/the-exploding-and-vanishing-gradients-problem-in-time-series-6b87d558d22\n\nhttps://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17","metadata":{}},{"cell_type":"markdown","source":"#### DO UPVOTE ⬆️⬆️⬆️⬆️⬆️⬆️\n#### DO COMMENT 💬💬💬💬💬💬💬💬\n#### Feel free to post for suggestions 💬💬💬💬💬💬💬💬\n<img src =\"https://i.pinimg.com/originals/f5/f1/26/f5f12634f6378186aa4f88455b122eda.gif\" width=1000 height=800>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}